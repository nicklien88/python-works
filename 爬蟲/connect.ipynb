{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "歡迎來到 Pycone 松果城市！\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "\n",
    "resp = requests.get('https://jwlin.github.io/py-scraping-analysis-book/ch1/connect.html')\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "print(soup.find('h1').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "狂圈粉！韓國瑜上《博恩》效果卓越 網估年輕票將大增\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "resp = requests.get('https://news.google.com/?hl=zh-TW&gl=TW&ceid=TW%3Azh-Hant')\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "print(soup.find('h3').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "歡迎來到 Pycone 松果城市！\n",
      "Exception: 'NoneType' object has no attribute 'text'\n",
      "None\n",
      "Exception: HTTPConnectionPool(host='non-existed.domain', port=80): Max retries exceeded with url: /connect.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019043010F88>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def main():\n",
    "    url_1 = \"http://blog.castman.net/web-crawler-tutorial/ch1/connect.html\"\n",
    "    bad_url = \"http://non-existed.domain/connect.html\"\n",
    "    text_1 = get_tag_text(url_1, 'h1')\n",
    "    print(text_1)\n",
    "    text_2 = get_tag_text(url_1, 'h2')\n",
    "    print(text_2)\n",
    "    text_3 = get_tag_text(bad_url, 'h3')\n",
    "    print(text_3)\n",
    "    \n",
    "def get_tag_text(url, tag):\n",
    "    try:\n",
    "        resp = requests.get(url)\n",
    "        if resp.status_code == 200:\n",
    "            soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "            return soup.find(tag).text\n",
    "    except Exception as e:\n",
    "        print(\"Exception: %s\" %(e))\n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['開發環境設定', 'Mac使用者', '在Mac環境下安裝Python與Sublime Text3', 'Read More']\n",
      "['資料科學', '給初學者的 Python 網頁爬蟲與資料分析', '(1) 前言', 'Read More']\n",
      "['資料科學', '給初學者的 Python 網頁爬蟲與資料分析', '(2) 套件安裝與啟動網頁爬蟲', 'Read More']\n",
      "['資料科學', '給初學者的 Python 網頁爬蟲與資料分析', '(3) 解構並擷取網頁資料', 'Read More']\n",
      "['資料科學', '給初學者的 Python 網頁爬蟲與資料分析', '(4) 擷取資料及下載圖片', 'Read More']\n",
      "['資料科學', '給初學者的 Python 網頁爬蟲與資料分析', '(5) 資料分析及展示', 'Read More']\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get('http://blog.castman.net/py-scraping-analysis-book/ch2/blog/blog.html')\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "divs = soup.find_all('div', 'content')\n",
    "for div in divs:\n",
    "    print([s for s in div.stripped_strings])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823.3333333333333\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get('http://blog.castman.net/py-scraping-analysis-book/ch2/table/table.html')\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "prices = []\n",
    "rows = soup.find('table', 'table').tbody.find_all('tr')\n",
    "for row in rows:\n",
    "    price = row.find_all('td')[2].text\n",
    "    prices.append(int(price))\n",
    "print(sum(prices)/len(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823.3333333333333\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get('http://blog.castman.net/py-scraping-analysis-book/ch2/table/table.html')\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "prices = []\n",
    "links = soup.find_all('a')\n",
    "for link in links:\n",
    "    price = link.parent.previous_sibling.text\n",
    "    prices.append(int(price))\n",
    "print(sum(prices)/len(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初心者 - Python入門 初學者 1490 http://www.pycone.com img/python-logo.png\n",
      "Python 網頁爬蟲入門實戰 有程式基礎的初學者 1890 http://www.pycone.com img/python-logo.png\n",
      "Python 機器學習入門實戰 (預計) 有程式基礎的初學者 1890 http://www.pycone.com img/python-logo.png\n",
      "Python 資料科學入門實戰 (預計) 有程式基礎的初學者 1890 http://www.pycone.com img/python-logo.png\n",
      "Python 資料視覺化入門實戰 (預計) 有程式基礎的初學者 1890 http://www.pycone.com img/python-logo.png\n",
      "Python 網站架設入門實戰 (預計) 有程式基礎的初學者 1890 None img/python-logo.png\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get('http://blog.castman.net/py-scraping-analysis-book/ch2/table/table.html')\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "rows = soup.find('table', 'table').tbody.find_all('tr')\n",
    "for row in rows:\n",
    "    all_tds = row.find_all('td')\n",
    "    if 'href' in all_tds[3].a.attrs:\n",
    "        href = all_tds[3].a['href']\n",
    "    else:\n",
    "        href = None\n",
    "    print(all_tds[0].text, all_tds[1].text, all_tds[2].text, href, all_tds[3].a.img['src'])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
