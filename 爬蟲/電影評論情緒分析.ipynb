{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 [['[好雷] 《暴走曼哈頓》黑豹化身正義猛警抽絲剝繭', '/bbs/movie/M.1575041152.A.537.html'], ['[好雷]  黑豹 --其實蠻好看的', '/bbs/movie/M.1552276420.A.F6F.html'], ['[好雷?] 黑豹 自慰片的新高度', '/bbs/movie/M.1545317279.A.EFC.html']]\n",
      "27 [['[負雷]黑豹-失衡的烏托邦', '/bbs/movie/M.1529245622.A.AF5.html'], ['[負雷] 四不像的黑豹', '/bbs/movie/M.1527918611.A.56C.html'], ['[微負雷] 黑豹有點讓人失望....', '/bbs/movie/M.1527839684.A.EF0.html']]\n",
      "處理 [好雷] 《暴走曼哈頓》黑豹化身正義猛警抽絲剝繭 /bbs/movie/M.1575041152.A.537.html\n",
      "處理 [好雷]  黑豹 --其實蠻好看的 /bbs/movie/M.1552276420.A.F6F.html\n",
      "處理 [好雷?] 黑豹 自慰片的新高度 /bbs/movie/M.1545317279.A.EFC.html\n",
      "處理 [二刷好雷] 水行俠真的不是黑豹 /bbs/movie/M.1545065816.A.46A.html\n",
      "處理 [好雷] 盲點：關於《黑豹》的奧克蘭也關於你我的故事 /bbs/movie/M.1538060300.A.8FD.html\n",
      "處理 [好雷] 瘋狂亞洲富豪─絕不是新加坡黑豹 /bbs/movie/M.1536676591.A.C8F.html\n",
      "處理 [微好雷]《雷神索爾3諸神黃昏》＆《黑豹》 /bbs/movie/M.1536217925.A.B6E.html\n",
      "處理 [好雷] 比黑豹好看的蟻人與黃蜂女 /bbs/movie/M.1531217457.A.6C8.html\n",
      "處理 [好雷]黑豹 — 符合台灣政治的隱喻分析 /bbs/movie/M.1525369009.A.CFA.html\n",
      "處理 [好雷] 黑豹：一部政治寓言 /bbs/movie/M.1521128014.A.19B.html\n",
      "處理 [好雷]黑豹，好看但可惜的反派 /bbs/movie/M.1520467155.A.8E5.html\n",
      "處理 [好雷] 黑豹心得 /bbs/movie/M.1519920385.A.14A.html\n",
      "處理 [ 好雷] 唯一缺憾的黑豹 /bbs/movie/M.1519908058.A.B99.html\n",
      "處理 [好雷] 黑豹 感想 微負評 /bbs/movie/M.1519841715.A.3BF.html\n",
      "處理 [核心好雷] 黑豹-科技與部落的反差萌 人權與人道議題 /bbs/movie/M.1519812809.A.DC3.html\n",
      "處理 [普好雷] 立體的世界，被一掌拍平，淺談【黑豹】 /bbs/movie/M.1519787493.A.BFD.html\n",
      "處理 [有意見好雷] 比上沒得比，比下有餘的黑豹 /bbs/movie/M.1519734682.A.979.html\n",
      "處理 [好雷] 黑豹 ~ 屬於黑人的童話故事 /bbs/movie/M.1519618436.A.EA0.html\n",
      "處理 [ 好 雷] 黑豹 /bbs/movie/M.1519572758.A.D3C.html\n",
      "處理 [好雷]黑豹 王者的抉擇 /bbs/movie/M.1519544126.A.E20.html\n",
      "處理 [好雷] 黑豹就真的很好看咩~ /bbs/movie/M.1519356550.A.A17.html\n",
      "處理 [ 普好雷] 黑豹 /bbs/movie/M.1519142286.A.7CD.html\n",
      "處理 [好雷] 黑豹 /bbs/movie/M.1519070229.A.DE9.html\n",
      "處理 [好雷] 黑豹：王者路大不易 /bbs/movie/M.1519042966.A.803.html\n",
      "處理 [微好雷]《黑豹》　春秋五霸的基本套路 /bbs/movie/M.1518991149.A.BDD.html\n",
      "處理 [好雷]黑豹 不太一樣的超級英雄 /bbs/movie/M.1518963410.A.A2E.html\n",
      "處理 [好雷] 黑豹 其實我比較喜歡反派@@ /bbs/movie/M.1518939706.A.D48.html\n",
      "處理 [負雷]黑豹-失衡的烏托邦 /bbs/movie/M.1529245622.A.AF5.html\n",
      "處理 [負雷] 四不像的黑豹 /bbs/movie/M.1527918611.A.56C.html\n",
      "處理 [微負雷] 黑豹有點讓人失望.... /bbs/movie/M.1527839684.A.EF0.html\n",
      "處理 [負雷] 是不是有精神分裂的黑豹 /bbs/movie/M.1526734538.A.5E2.html\n",
      "處理 [負雷] 黑豹 /bbs/movie/M.1520322497.A.E24.html\n",
      "處理 [負雷]黑豹  最差漫威電影 /bbs/movie/M.1519931938.A.207.html\n",
      "處理 [  微負雷] 黑豹 /bbs/movie/M.1519721961.A.471.html\n",
      "處理 [負雷] 黑豹 Black Panther，暴力與分享 /bbs/movie/M.1518961786.A.79E.html\n",
      "處理 [  負雷] 隨便拍拍隨便買單的「黑豹」 /bbs/movie/M.1518934190.A.F7B.html\n",
      "處理 [負雷] 只有政治正確的  黑豹 /bbs/movie/M.1518809750.A.4E0.html\n",
      "處理 [負雷]黑豹：除了美術視覺，其餘毫無魅力 /bbs/movie/M.1518808279.A.FC9.html\n",
      "處理 [睡負無雷] 看黑豹看到睡著 /bbs/movie/M.1518774686.A.889.html\n",
      "處理 [小負雷] 黑豹-請修邊幅可以嗎?(內有雷) /bbs/movie/M.1518761310.A.05C.html\n",
      "處理 [爛無雷] 千萬不要期待的黑豹 /bbs/movie/M.1518758578.A.8F0.html\n",
      "處理 [普負雷] 輸不起的黑豹 /bbs/movie/M.1518714311.A.957.html\n",
      "處理 [  負雷] 黑豹-鋪陳復3的跳板 /bbs/movie/M.1518684255.A.489.html\n",
      "處理 [ 負雷] 黑豹 /bbs/movie/M.1518670825.A.A31.html\n",
      "處理 [普負雷] 黑豹出戲點 /bbs/movie/M.1518642702.A.497.html\n",
      "處理 [負雷] 黑豹特遣隊 /bbs/movie/M.1518609915.A.835.html\n",
      "處理 [負雷] 家天下黑豹 /bbs/movie/M.1518596627.A.3E0.html\n",
      "處理 [負雷] 失望的黑豹(補個優點) /bbs/movie/M.1518577527.A.4BB.html\n",
      "處理 [負雷] 真的過譽的黑豹......... /bbs/movie/M.1518536086.A.B1E.html\n",
      "處理 [負雷] 黑豹天下 /bbs/movie/M.1518534403.A.ECB.html\n",
      "處理 [  負雷] 讓人失望的黑豹 /bbs/movie/M.1518529744.A.586.html\n",
      "處理 [普負雷]  一片歐罵罵的黑豹 /bbs/movie/M.1518513719.A.462.html\n",
      "處理 [微負雷] 黑豹 相較其他marvel片有點可惜 /bbs/movie/M.1518510319.A.1DC.html\n",
      "處理 [負雷]黑豹 /bbs/movie/M.1518495315.A.E27.html\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "def get_web_page(page_url):\n",
    "    resp = requests.get(page_url)\n",
    "    if resp.status_code != 200:\n",
    "        print(\"Invalid url:\", resp.url)\n",
    "        return None\n",
    "    else:\n",
    "        return resp.text\n",
    "\n",
    "\n",
    "def get_articles(dom):\n",
    "    soup = BeautifulSoup(dom, \"html.parser\")\n",
    "\n",
    "    # 若 <a>有 href 屬性, 代表有超連結\n",
    "    prev_link = soup.find(\"div\", \"btn-group-paging\").find_all(\"a\")[1]\n",
    "    prev_link = prev_link[\"href\"] if \"href\" in prev_link.attrs else None\n",
    "\n",
    "    # 瀏覽每一個文章所在區塊\n",
    "    positve_posts = []\n",
    "    negative_posts = []\n",
    "    for d in soup.find_all(\"div\", \"r-ent\"):\n",
    "        href = d.find(\"div\", \"title\").a[\"href\"]\n",
    "        title = d.find(\"div\", \"title\").text.strip()\n",
    "        # 若標題為 [] 開頭, e.g., [好雷]XXXX\n",
    "        if re.match(r\"\\[.*\\]\", title):\n",
    "            tag = re.match(r\"\\[.*\\]\", title).group(0)\n",
    "            # 標前內含'好'為好評; 含'負'或'爛'為負評\n",
    "            if \"好\" in tag:\n",
    "                positve_posts.append([title, href])\n",
    "            if \"負\" in tag or \"爛\" in tag:\n",
    "                negative_posts.append([title, href])\n",
    "    return prev_link, positve_posts, negative_posts\n",
    "\n",
    "\n",
    "def sanitize(txt):\n",
    "    # 保留英數字、中文(\\u4e00-\\u9fa5)、中文標點符號、部分特殊符號\n",
    "    # ^ 表示非括弧內指定的字元\n",
    "    expr = re.compile(r'[^\\u4e00-\\u9fa5。﹔，：＂（）、？「」『』【】\\s\\w:/\\-.()\"]')\n",
    "    txt = re.sub(expr, \"\", txt)\n",
    "    # 用空白取代中英文標點\n",
    "    txt = re.sub(r'[。﹔，：＂（）、？「」『』【】:/\\-.()\"]', \" \", txt)\n",
    "    txt = re.sub(r'(\\s)+', ' ', txt)  # 用單一空白取代多個換行或 tab 符號\n",
    "    txt = txt.replace(\"--\", \"\")\n",
    "    txt.lower()  # 英文字轉為小寫\n",
    "    return txt\n",
    "\n",
    "\n",
    "def get_post(post_url):\n",
    "    resp = requests.get(url=post_url, cookies={\"over18\": \"1\"})\n",
    "    soup = BeautifulSoup(resp.text, \"html5lib\")\n",
    "    main_content = soup.find(\"div\", id=\"main-content\")\n",
    "\n",
    "    # 把非本文的部分()標題區及推文區移除\n",
    "    # 移除標題區塊\n",
    "    for meta in main_content.find_all(\"div\", \"article-metaline\"):\n",
    "        meta.extract()\n",
    "    # 移除推文區塊\n",
    "    for push in main_content.find_all(\"div\", \"push\"):\n",
    "        push.extract()\n",
    "\n",
    "    parsed = []\n",
    "\n",
    "    # 移除 '※ 發信站:', '--'開頭, 本文區最後一行的文章網址\n",
    "    for txt in main_content.stripped_strings:\n",
    "        if txt[0] == \"※\" or txt[:2] == \"--\" or post_url in txt:\n",
    "            continue\n",
    "        txt = sanitize(txt)\n",
    "        if txt:\n",
    "            parsed.append(txt)\n",
    "    return \" \".join(parsed)\n",
    "\n",
    "def get_article_body(csv_file):\n",
    "    id_to_body = {}\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            print(\"處理\", row[\"title\"], row[\"href\"])\n",
    "            title = \" \".join(row[\"title\"].split(\"]\")[1:])\n",
    "            title = sanitize(title)\n",
    "            body = get_post(PTT_URL + row[\"href\"])\n",
    "            # 以文章超連結為 key, 標題 + 本文為 value\n",
    "            id_to_body[row[\"href\"]] = title + \" \" + body\n",
    "            time.sleep(1)  # 放慢爬蟲速度\n",
    "    return id_to_body\n",
    "\n",
    "\n",
    "# 主程式流程\n",
    "PTT_URL = \"https://www.ptt.cc\"\n",
    "start_url = PTT_URL + \"/bbs/movie/search?page=1&q=黑豹\"\n",
    "page = get_web_page(start_url)\n",
    "positve_posts, negative_posts = [], []\n",
    "if page:\n",
    "\n",
    "    prev_link, pos, neg = get_articles(page)\n",
    "    positve_posts += pos\n",
    "    negative_posts += neg\n",
    "\n",
    "    while prev_link:\n",
    "        url = PTT_URL + prev_link\n",
    "        next_page = get_web_page(url)\n",
    "        prev_link, pos, neg = get_articles(next_page)\n",
    "        positve_posts += pos\n",
    "        negative_posts += neg\n",
    "\n",
    "# 顯示 正負評的數量及前三篇貼文\n",
    "print(len(positve_posts), positve_posts[:3])\n",
    "print(len(negative_posts), negative_posts[:3])\n",
    "\n",
    "with open(\"mov_pos.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"title\", \"href\"])\n",
    "    writer.writerows(positve_posts[:27])  # 因為負評文章只有27篇，為了讓機器學習沒有偏向某一邊，所以已取27篇好評\n",
    "\n",
    "with open(\"mov_neg.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"title\", \"href\"])\n",
    "    writer.writerows(negative_posts)\n",
    "\n",
    "d1 = get_article_body(\"mov_pos.csv\")\n",
    "d2 = get_article_body(\"mov_neg.csv\")\n",
    "id_to_body = {**d1, **d2}  # 將兩個 dict 合併成一個\n",
    "with open(\"id_to_body.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(id_to_body, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['暴走', '曼哈頓', '黑豹', '化身', '正義猛警'] 正評\n",
      "['黑豹', '其實', '好看', 'movie', '最近'] 正評\n",
      "['黑豹', '自慰', '高度', 'movie', '最近'] 正評\n",
      "['黑豹', '失衡', '烏托邦', 'movie', '以下'] 負評\n",
      "['四不像', '黑豹', 'movie', '首先', '主角'] 負評\n",
      "['黑豹', '有點', '失望', 'movie', '前陣子'] 負評\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import csv\n",
    "import json\n",
    "\n",
    "def load_data(a_csv, b_json, label):\n",
    "    a_ids = []\n",
    "    with open(a_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            a_ids.append(row[\"href\"])\n",
    "    with open(b_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        id_to_body = json.load(f)\n",
    "    \n",
    "    data = []\n",
    "    for a_id in a_ids:\n",
    "        tokenized_post = []\n",
    "        txt = id_to_body[a_id]\n",
    "        for sent in txt.split(): # 將文章切成句子\n",
    "            # 斷句後的結果, 若非空白且長度為 2 以上,則列入詞庫\n",
    "            filterd = [t for t in jieba.cut(sent) if t.split() and len(t) > 1]\n",
    "            tokenized_post += filterd\n",
    "        data.append([tokenized_post, label])\n",
    "    return data\n",
    "\n",
    "# 主程式流程\n",
    "pos_data = load_data(\"mov_pos.csv\", \"id_to_body.json\", \"正評\")\n",
    "neg_data = load_data(\"mov_neg.csv\", \"id_to_body.json\", \"負評\")\n",
    "\n",
    "# 印出正評與負評文章前幾個字，確認資料無誤\n",
    "for post, label in pos_data[:3]:\n",
    "    print(post[:5], label)\n",
    "for post, label in neg_data[:3]:\n",
    "    print(post[:5], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 打亂資料順序\n",
    "random.seed(42)\n",
    "random.shuffle(pos_data)\n",
    "random.shuffle(neg_data)\n",
    "\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "# 前 22 筆資料及答案放進 training set\n",
    "# 建立資料時要用空白將斷好的詞組成一個字串\n",
    "# 以便以後用 scikit learn 建立字典並將文字資料轉換成向量\n",
    "for i in range(22):\n",
    "    x_train.append(\" \".join(pos_data[i][0]))\n",
    "    x_train.append(\" \".join(neg_data[i][0]))\n",
    "    y_train.append(pos_data[i][1])\n",
    "    y_train.append(neg_data[i][1])\n",
    "\n",
    "# 最後 5 筆資料及答案放進 testing set\n",
    "for i in range(22, len(pos_data)):\n",
    "    x_test.append(\" \".join(pos_data[i][0]))\n",
    "    x_test.append(\" \".join(neg_data[i][0]))\n",
    "    y_test.append(pos_data[i][1])\n",
    "    y_test.append(neg_data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測結果: ['正評', '負評', '負評', '負評', '正評', '負評', '負評', '負評', '正評', '負評']\n",
      "正確答案: ['正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評', '正評', '負評']\n",
      "正確率: 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "# CountVectorizer 及 TfidfTransformer 模組是用來計算 TF-IDF\n",
    "# TF-IDF（Term Frequency-InversDocument Frequency）是一种常用于信息处理和数据挖掘的加权技术。\n",
    "# 该技术采用一种统计方法，根据字词的在文本中出现的次数和在整个语料中出现的文档频率来计算一个字词在整个语料中的重要程度。\n",
    "# 它的优点是能过滤掉一些常见的却无关紧要本的词语，同时保留影响整个文本的重要字词。计算方法如下面公式所示。\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "transformer = TfidfTransformer()\n",
    "x_train = transformer.fit_transform(x_train)\n",
    "clf = SGDClassifier(random_state=42) # 宣告SVM (Support Vector Machine)模型\n",
    "clf.fit(x_train, y_train)\n",
    "x_test = vectorizer.transform(x_test)\n",
    "x_test = transformer.transform(x_test)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"預測結果:\", list(y_pred))\n",
    "print(\"正確答案:\", y_test)\n",
    "print(\"正確率:\", accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['這部', '電影', '給我', '很大', '啟發']\n",
      "['真的', '覺得', '浪費']\n",
      "['正評' '負評']\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"這部 電影 給我 很大 的 啟發\", \n",
    "             \"真的 覺得 浪費 錢\"]\n",
    "analyze = vectorizer.build_analyzer()\n",
    "print(analyze(sentences[0]))\n",
    "print(analyze(sentences[1]))\n",
    "custom_data = transformer.transform(vectorizer.transform(sentences))\n",
    "print(clf.predict(custom_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
